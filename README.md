# GAN Image Generation with TensorFlow 2.x

This project demonstrates the implementation and training of a Generative Adversarial Network (GAN) to generate synthetic images from random noise using TensorFlow 2.x. The GAN consists of two neural networks: a Generator that produces images and a Discriminator that classifies them as real or fake. These networks are trained simultaneously in a game-theoretic scenario.

## Table of Contents
- [Introduction](#introduction)
- [Architecture](#architecture)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Training](#training)
- [Results](#results)
- [License](#license)

## Introduction
A Generative Adversarial Network (GAN) is a class of machine learning models in which two networks—the Generator and the Discriminator—compete against each other in a zero-sum game. The goal of the Generator is to produce data that is indistinguishable from real data, while the Discriminator's task is to classify real from generated data.

This repository implements a basic GAN for generating images from noise. The model is trained to generate 28x28 images (like MNIST digits) and visualizes the results.

## Architecture
- **Generator**: Takes random noise as input and generates synthetic images.
- **Discriminator**: Classifies images as real or fake. It tries to distinguish between real images (from the dataset) and fake ones (generated by the Generator).
- Loss functions: Sigmoid cross-entropy loss is used to evaluate both the Generator and Discriminator.
- Optimizers: Adam optimizers are used to update the weights of both networks.

## Requirements
- Python 3.x
- TensorFlow 2.x
- NumPy
- Matplotlib

You can install the required libraries using `pip`:
```bash
pip install tensorflow numpy matplotlib
```

## Installation

### Clone this repository:
```bash
git clone https://github.com/saranshtyagi/generative-adversial-networks
.git
```

## Usage 
You can train the GAN model or use it to generate images.

## Training 
- The GAN model is trained for a specified number of epochs.
- Random noise is used as input to the Generator, and the generated images are fed to the Discriminator for classification.
- The model optimizes the adversarial game between Generator and Discriminator using backpropagation and gradient descent.

### Sample Output
The model will display progress of the Generator and Discriminator losses during training, and after every 2000 epochs, it will print the following:
```bash
Epoch: <epoch_number>, Generator Loss: <loss>, Discriminator Loss: <loss>
```

## Results
After training, you can visualize the generated images. These will be grayscale images, typically of size 28x28 (suitable for MNIST-like datasets).

## License
This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.
